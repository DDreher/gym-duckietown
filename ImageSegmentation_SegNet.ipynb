{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "outputs": [],
      "source": "import tensorflow as tf\nfrom tensorflow.python.keras.models import Model\nfrom tensorflow.python.keras import backend as keras_backend\nfrom tensorflow.python.keras.layers import Layer, Input, Dense, Conv2D, Activation, BatchNormalization, Reshape\nimport pandas as pd\nfrom os import walk as walk\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "outputs": [],
      "source": "PATH_DATA \u003d \u0027./ImageSegData/\u0027\nDIR_LABELS \u003d \u0027labels\u0027\nDIR_IMAGES \u003d \u0027images\u0027\n\nPATH_LABELS \u003d PATH_DATA+DIR_LABELS\nPATH_IMAGES \u003d PATH_DATA+DIR_IMAGES\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "# SegNet\nLink to paper: https://arxiv.org/abs/1511.00561",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Custom Layers\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "outputs": [],
      "source": "\nclass MaxPoolingWithArgmax2D(Layer):       \n    \"\"\"Keras Wrapper around tf.nn.max_pool_with_argmax.\n    Return the pooled output and the corresponding max indices\n    \"\"\"\n    def __init__(self, pool_size\u003d(2,2), strides\u003d(2,2), padding\u003d\u0027same\u0027, **kwargs):\n        super(MaxPoolingWithArgmax2D, self).__init__(**kwargs)\n        self.pool_size \u003d pool_size\n        self.strides \u003d strides\n        self.padding \u003d padding\n        \n    def call(self, inputs, **kwargs):\n        padding \u003d self.padding\n        pool_size \u003d self.pool_size\n        strides \u003d self.strides\n        ksize \u003d [1, pool_size[0], pool_size[1], 1] # byxc\n        padding \u003d padding.upper()\n        strides \u003d [1, strides[0], strides[1], 1]\n        output, argmax \u003d tf.nn.max_pool_with_argmax(\n                                                    inputs,\n                                                    ksize\u003dksize,\n                                                    strides\u003dstrides,\n                                                    padding\u003dpadding)\n        argmax \u003d tf.cast(argmax, keras_backend.floatx())\n        return [output, argmax]\n    \nclass MaxUpsampling2D(Layer):       \n    \"\"\"Keras Wrapper around tf.nn.max_pool_with_argmax.\n    Return the pooled output and the corresponding max indices\n    \"\"\"\n    def __init__(self, size\u003d(2, 2), **kwargs):\n        super(MaxUpsampling2D, self).__init__(**kwargs)\n        self.size \u003d size\n        \n    def call(self, inputs, output_shape\u003dNone):\n        updates, mask \u003d inputs[0], inputs[1]\n        with tf.variable_scope(self.name):\n            mask \u003d keras_backend.cast(mask, \u0027int32\u0027)\n            input_shape \u003d tf.shape(updates, out_type\u003d\u0027int32\u0027)\n            #  Calculate new shape\n            if output_shape is None:\n                output_shape \u003d (\n                        input_shape[0],\n                        input_shape[1]*self.size[0],\n                        input_shape[2]*self.size[1],\n                        input_shape[3])\n            self.output_shape1 \u003d output_shape\n\n            # calculation indices for batch, height, width and feature maps\n            one_like_mask \u003d tf.ones_like(mask, dtype\u003d\u0027int32\u0027)\n            batch_shape \u003d tf.concat(\n                    [[input_shape[0]], [1], [1], [1]],\n                    axis\u003d0)\n            batch_range \u003d tf.reshape(\n                    tf.range(output_shape[0], dtype\u003d\u0027int32\u0027),\n                    shape\u003dbatch_shape)\n            b \u003d one_like_mask * batch_range\n            y \u003d mask // (output_shape[2] * output_shape[3])\n            x \u003d (mask // output_shape[3]) % output_shape[2]\n            feature_range \u003d tf.range(output_shape[3], dtype\u003d\u0027int32\u0027)\n            f \u003d one_like_mask * feature_range\n\n            # transpose indices \u0026 reshape update values to one dimension\n            updates_size \u003d tf.size(updates)\n            indices \u003d tf.transpose(keras_backend.reshape(\n                tf.stack([b, y, x, f]),\n                [4, updates_size]))\n            values \u003d tf.reshape(updates, [updates_size])\n            ret \u003d tf.scatter_nd(indices, values, output_shape)\n            return ret\n        ",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "outputs": [],
      "source": "def build_segnet(input_shape, num_classes, kernel_size\u003d3, pool_size\u003d(2,2)):\n    # Encoder pass\n    inputs \u003d Input(shape\u003dinput_shape)\n    \n    conv_1 \u003d Conv2D(filters\u003d64, kernel_size\u003dkernel_size, padding\u003d\u0027same\u0027)(inputs)\n    batch_norm_1 \u003d BatchNormalization()(conv_1)\n    act_1 \u003d Activation(\u0027relu\u0027)(batch_norm_1)\n    conv_2 \u003d Conv2D(filters\u003d64, kernel_size\u003dkernel_size, padding\u003d\u0027same\u0027)(act_1)\n    batch_norm_2 \u003d BatchNormalization()(conv_2)\n    act_2 \u003d Activation(\u0027relu\u0027)(batch_norm_2)\n    max_pool_1, max_indices_1 \u003d MaxPoolingWithArgmax2D(pool_size)(act_2)\n    \n    conv_3 \u003d Conv2D(filters\u003d128, kernel_size\u003dkernel_size, padding\u003d\u0027same\u0027)(max_pool_1)\n    batch_norm_3 \u003d BatchNormalization()(conv_3)\n    act_3 \u003d Activation(\u0027relu\u0027)(batch_norm_3)\n    conv_4 \u003d Conv2D(filters\u003d128, kernel_size\u003dkernel_size, padding\u003d\u0027same\u0027)(act_3)\n    batch_norm_4 \u003d BatchNormalization()(conv_4)\n    act_4 \u003d Activation(\u0027relu\u0027)(batch_norm_4)\n    max_pool_2, max_indices_2 \u003d MaxPoolingWithArgmax2D(pool_size)(act_4)\n    \n    conv_5 \u003d Conv2D(filters\u003d256, kernel_size\u003dkernel_size, padding\u003d\u0027same\u0027)(max_pool_2)\n    batch_norm_5 \u003d BatchNormalization()(conv_5)\n    act_5 \u003d Activation(\u0027relu\u0027)(batch_norm_5)\n    conv_6 \u003d Conv2D(filters\u003d256, kernel_size\u003dkernel_size, padding\u003d\u0027same\u0027)(act_5)\n    batch_norm_6 \u003d BatchNormalization()(conv_6)\n    act_6 \u003d Activation(\u0027relu\u0027)(batch_norm_6)\n    conv_7 \u003d Conv2D(filters\u003d256, kernel_size\u003dkernel_size, padding\u003d\u0027same\u0027)(act_6)\n    batch_norm_7 \u003d BatchNormalization()(conv_7)\n    act_7 \u003d Activation(\u0027relu\u0027)(batch_norm_7)\n    max_pool_3, max_indices_3 \u003d MaxPoolingWithArgmax2D(pool_size)(act_7)\n    \n    conv_8 \u003d Conv2D(filters\u003d512, kernel_size\u003dkernel_size, padding\u003d\u0027same\u0027)(max_pool_3)\n    batch_norm_8 \u003d BatchNormalization()(conv_8)\n    act_8 \u003d Activation(\u0027relu\u0027)(batch_norm_8)\n    conv_9 \u003d Conv2D(filters\u003d512, kernel_size\u003dkernel_size, padding\u003d\u0027same\u0027)(act_8)\n    batch_norm_9 \u003d BatchNormalization()(conv_9)\n    act_9 \u003d Activation(\u0027relu\u0027)(batch_norm_9)\n    conv_10 \u003d Conv2D(filters\u003d512, kernel_size\u003dkernel_size, padding\u003d\u0027same\u0027)(act_9)\n    batch_norm_10 \u003d BatchNormalization()(conv_10)\n    act_10 \u003d Activation(\u0027relu\u0027)(batch_norm_10)\n    max_pool_4, max_indices_4 \u003d MaxPoolingWithArgmax2D(pool_size)(act_10)\n    \n    conv_11 \u003d Conv2D(filters\u003d512, kernel_size\u003dkernel_size, padding\u003d\u0027same\u0027)(max_pool_4)\n    batch_norm_11 \u003d BatchNormalization()(conv_11)\n    act_11 \u003d Activation(\u0027relu\u0027)(batch_norm_11)\n    conv_12 \u003d Conv2D(filters\u003d512, kernel_size\u003dkernel_size, padding\u003d\u0027same\u0027)(act_11)\n    batch_norm_12 \u003d BatchNormalization()(conv_12)\n    act_12 \u003d Activation(\u0027relu\u0027)(batch_norm_12)\n    conv_13 \u003d Conv2D(filters\u003d512, kernel_size\u003dkernel_size, padding\u003d\u0027same\u0027)(act_12)\n    batch_norm_13 \u003d BatchNormalization()(conv_13)\n    act_13 \u003d Activation(\u0027relu\u0027)(batch_norm_13)\n    max_pool_5, max_indices_5 \u003d MaxPoolingWithArgmax2D(pool_size)(act_13)\n    \n    # Decoder pass\n    upsampling_1 \u003d MaxUpsampling2D(pool_size)([max_pool_5, max_indices_5])\n    conv_14 \u003d Conv2D(filters\u003d512, kernel_size\u003dkernel_size, padding\u003d\u0027same\u0027)(upsampling_1)\n    batch_norm_14 \u003d BatchNormalization()(conv_14)\n    act_14 \u003d Activation(\u0027relu\u0027)(batch_norm_14)\n    conv_15 \u003d Conv2D(filters\u003d512, kernel_size\u003dkernel_size, padding\u003d\u0027same\u0027)(act_14)\n    batch_norm_15 \u003d BatchNormalization()(conv_15)\n    act_15 \u003d Activation(\u0027relu\u0027)(batch_norm_15)\n    conv_16 \u003d Conv2D(filters\u003d512, kernel_size\u003dkernel_size, padding\u003d\u0027same\u0027)(act_15)\n    batch_norm_16 \u003d BatchNormalization()(conv_16)\n    act_16 \u003d Activation(\u0027relu\u0027)(batch_norm_16)\n    \n    upsampling_2 \u003d MaxUpsampling2D(pool_size)([act_16, max_indices_4])\n    conv_17 \u003d Conv2D(filters\u003d512, kernel_size\u003dkernel_size, padding\u003d\u0027same\u0027)(upsampling_2)\n    batch_norm_17 \u003d BatchNormalization()(conv_17)\n    act_17 \u003d Activation(\u0027relu\u0027)(batch_norm_17)\n    conv_18 \u003d Conv2D(filters\u003d512, kernel_size\u003dkernel_size, padding\u003d\u0027same\u0027)(act_17)\n    batch_norm_18 \u003d BatchNormalization()(conv_18)\n    act_18 \u003d Activation(\u0027relu\u0027)(batch_norm_18)\n    conv_19 \u003d Conv2D(filters\u003d512, kernel_size\u003dkernel_size, padding\u003d\u0027same\u0027)(act_18)\n    batch_norm_19 \u003d BatchNormalization()(conv_19)\n    act_19 \u003d Activation(\u0027relu\u0027)(batch_norm_19)\n    \n    upsampling_3 \u003d MaxUpsampling2D(pool_size)([act_19, max_indices_3])\n    conv_20 \u003d Conv2D(filters\u003d256, kernel_size\u003dkernel_size, padding\u003d\u0027same\u0027)(upsampling_3)\n    batch_norm_20 \u003d BatchNormalization()(conv_20)\n    act_20 \u003d Activation(\u0027relu\u0027)(batch_norm_20)\n    conv_21 \u003d Conv2D(filters\u003d256, kernel_size\u003dkernel_size, padding\u003d\u0027same\u0027)(act_20)\n    batch_norm_21 \u003d BatchNormalization()(conv_21)\n    act_21 \u003d Activation(\u0027relu\u0027)(batch_norm_21)\n    conv_22 \u003d Conv2D(filters\u003d256, kernel_size\u003dkernel_size, padding\u003d\u0027same\u0027)(act_21)\n    batch_norm_22 \u003d BatchNormalization()(conv_22)\n    act_22 \u003d Activation(\u0027relu\u0027)(batch_norm_22)\n    \n    upsampling_4 \u003d MaxUpsampling2D(pool_size)([act_22, max_indices_2])\n    conv_23 \u003d Conv2D(filters\u003d128, kernel_size\u003dkernel_size, padding\u003d\u0027same\u0027)(upsampling_4)\n    batch_norm_23 \u003d BatchNormalization()(conv_23)\n    act_23 \u003d Activation(\u0027relu\u0027)(batch_norm_23)\n    conv_24 \u003d Conv2D(filters\u003d128, kernel_size\u003dkernel_size, padding\u003d\u0027same\u0027)(act_23)\n    batch_norm_24 \u003d BatchNormalization()(conv_24)\n    act_24 \u003d Activation(\u0027relu\u0027)(batch_norm_24)\n    \n    upsampling_5 \u003d MaxUpsampling2D(pool_size)([act_24, max_indices_1])\n    conv_25 \u003d Conv2D(filters\u003d64, kernel_size\u003dkernel_size, padding\u003d\u0027same\u0027)(upsampling_3)\n    batch_norm_25 \u003d BatchNormalization()(conv_25)\n    act_25 \u003d Activation(\u0027relu\u0027)(batch_norm_25)\n    conv_26 \u003d Conv2D(filters\u003dnum_classes, kernel_size\u003d(1,1), padding\u003d\u0027valid\u0027)(act_25)\n    batch_norm_26 \u003d BatchNormalization()(conv_26)\n    \n    outputs \u003d Reshape(target_shape\u003d(input_shape[0]*input_shape[1], num_classes),\n                      input_shape\u003d(input_shape[0], input_shape[1], num_classes))(batch_norm_26)\n    \n    outputs \u003d Activation(\u0027relu\u0027)(outputs)\n    \n    return Model(inputs\u003dinputs, outputs\u003doutputs, name\u003d\"SegNet\")\n       ",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "# Pipeline\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "outputs": [],
      "source": "batch_size\u003d16\nlabels \u003d []\nfor (dirpath, dirnames, filenames) in walk(PATH_LABELS):\n    for name in filenames:\n        path \u003d dirpath+\u0027/\u0027+name\n        labels.append(path)\n\nimages \u003d []\nfor (dirpath, dirnames, filenames) in walk(PATH_IMAGES):\n    for name in filenames:\n        path \u003d dirpath+\u0027/\u0027+name\n        images.append(path)\n\n# Create a dataset (image, label)-pairs\nds \u003d tf.data.Dataset.from_tensor_slices((images, labels))\n\ndef load_and_preprocess_from_paths(image_path, label_path):\n    image_raw \u003d tf.read_file(image_path)\n    label_raw \u003d tf.read_file(label_path)\n\n    # TODO: PREPROCESSING (Normalization..)\n    image \u003d tf.image.decode_png(image_raw, channels\u003d3)\n    label \u003d tf.image.decode_png(label_raw, channels\u003d3) \n    return image, label\n\nimage_label_ds \u003d ds.map(load_and_preprocess_from_paths)\nimage_label_ds \u003d image_label_ds.shuffle(buffer_size\u003d3)\nimage_label_ds \u003d image_label_ds.repeat()\nimage_label_ds \u003d image_label_ds.batch(batch_size)\n#image_label_ds \u003d image_label_ds.prefetch(buffer_size\u003dAUTOTUNE)\n\n# create general iterator\niterator \u003d tf.data.Iterator.from_structure(image_label_ds.output_types,\n                                       image_label_ds.output_shapes)\n\nnext_element \u003d iterator.get_next()\ntraining_init_op \u003d iterator.make_initializer(image_label_ds)\n\n# with tf.Session() as session:\n#     session.run(tf.local_variables_initializer())\n#     session.run(tf.global_variables_initializer())\n#     session.run(training_init_op)\n# \n#     for step in range(max_steps):\n#         feed_dict \u003d {self.inputs_pl: next_element}\n#         print(session.run(next_element))       \n         ",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "# Train SegNet\n                ",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "outputs": [
        {
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m\u003cipython-input-24-c87514bc7a0d\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[1;34m\u001b[0m\n\u001b[1;32m----\u003e 1\u001b[1;33m \u001b[0msegnet\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[0mbuild_segnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m640\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m480\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msegnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m\u003cipython-input-20-c0b9353bb0a4\u003e\u001b[0m in \u001b[0;36mbuild_segnet\u001b[1;34m(input_shape, num_classes, kernel_size, pool_size)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;31m# Decoder pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[0mupsampling_1\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[0mMaxUpsampling2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmax_pool_5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_indices_5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---\u003e 56\u001b[1;33m     \u001b[0mconv_14\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m\u003d\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m\u003d\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m\u003d\u001b[0m\u001b[1;34m\u0027same\u0027\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mupsampling_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m     \u001b[0mbatch_norm_14\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv_14\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mact_14\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[0mActivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\u0027relu\u0027\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_norm_14\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\Users\\Dani\\Anaconda3\\envs\\gym-duckietown\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    536\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m         \u001b[1;31m# Build layer if applicable (if the `build` method has been overridden).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--\u003e 538\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m         \u001b[1;31m# We must set self.built since user defined build functions are not\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;31m# constrained to set self.built.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\Users\\Dani\\Anaconda3\\envs\\gym-duckietown\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   1601\u001b[0m     \u001b[1;31m# Only call `build` if the user has manually overridden the build method.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1602\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\u0027_is_default\u0027\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-\u003e 1603\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1605\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\Users\\Dani\\Anaconda3\\envs\\gym-duckietown\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\convolutional.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    151\u001b[0m       \u001b[0mchannel_axis\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdims\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mchannel_axis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--\u003e 153\u001b[1;33m       raise ValueError(\u0027The channel dimension of the inputs \u0027\n\u001b[0m\u001b[0;32m    154\u001b[0m                        \u0027should be defined. Found `None`.\u0027)\n\u001b[0;32m    155\u001b[0m     \u001b[0minput_dim\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mchannel_axis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mValueError\u001b[0m: The channel dimension of the inputs should be defined. Found `None`."
          ],
          "ename": "ValueError",
          "evalue": "The channel dimension of the inputs should be defined. Found `None`.",
          "output_type": "error"
        }
      ],
      "source": "segnet \u003d build_segnet((640,480,1), 5)\nsegnet.summary()",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "outputs": [
        {
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m\u003cipython-input-25-01a251291e3f\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[1;34m\u001b[0m\n\u001b[1;32m----\u003e 1\u001b[1;33m \u001b[0msegnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m\u003d\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m\u003d\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m\u003d\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name \u0027segnet\u0027 is not defined"
          ],
          "ename": "NameError",
          "evalue": "name \u0027segnet\u0027 is not defined",
          "output_type": "error"
        }
      ],
      "source": "segnet.fit(iterator, steps_per_epoch\u003dlen(images), epochs\u003d1, verbose\u003d1)\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "stem_cell": {
      "cell_type": "raw",
      "source": "",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}